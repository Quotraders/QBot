name: "24/7 Continuous ML/RL Trainer (Compliant)"

on:
  schedule:
    - cron: '*/30 * * * *'  # Every 30 minutes
  workflow_dispatch:         # Manual trigger
  push:
    branches: ['main']       # Also run on main branch updates

env:
  VENDOR_DIR: "data/vendor"
  DATA_DIR: "data/logs"

jobs:
  continuous-training:
    runs-on: ubuntu-latest
    
    steps:
      - name: "📥 Checkout Code"
        uses: actions/checkout@v4
        
      - name: "🐍 Setup Python"
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: "📦 Install ML Dependencies"
        run: |
          pip install --upgrade pip
          pip install torch torchvision numpy pandas scikit-learn
          pip install stable-baselines3[extra] 
          pip install ta onnx onnxruntime skl2onnx
          pip install matplotlib seaborn
          pip install awscli
          
      - name: "🔍 Check for Skip Condition"
        id: skip_check
        run: |
          echo "skip=false" >> $GITHUB_OUTPUT
          if [ -f "SKIP_TRAINING" ]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "Training skipped due to SKIP_TRAINING file"
          fi
          
      - name: "📥 Download Training Data from S3"
        if: steps.skip_check.outputs.skip == 'false'
        run: |
          mkdir -p ${{ env.DATA_DIR }} ${{ env.VENDOR_DIR }}
          
          # Download existing training data (if available)
          aws s3 sync "s3://${{ secrets.S3_BUCKET }}/logs/" "${{ env.DATA_DIR }}/" \
            --exclude "*" --include "candidates.*.parquet" \
            --quiet || echo "No existing data found"
          
          # Download vendor historical data for gap filling
          aws s3 sync "s3://${{ secrets.S3_BUCKET }}/vendor/" "${{ env.VENDOR_DIR }}/" \
            --exclude "*" --include "*.parquet" \
            --quiet || echo "No vendor data found"
            
          echo "Downloaded data files:"
          find ${{ env.DATA_DIR }} -name "*.parquet" -exec ls -lh {} \; || echo "No parquet files"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          
      - name: "🧮 Generate Vendor Features (Gap Fill)"
        if: steps.skip_check.outputs.skip == 'false'
        run: |
          cd ml
          python feature_gen_from_vendor.py
          echo "✅ Vendor feature generation completed"
          
      - name: "🔗 Merge All Training Data"
        if: steps.skip_check.outputs.skip == 'false'  
        run: |
          cd ml
          python merge_training_data.py ${{ env.DATA_DIR }} ${{ env.VENDOR_DIR }}
          
      - name: "🧠 Train Meta Strategy Classifier"
        if: steps.skip_check.outputs.skip == 'false'  
        run: |
          cd ml
          python train_meta_classifier.py ${{ env.DATA_DIR }}/candidates.merged.parquet models
          
      - name: "⚡ Train Execution Quality Predictor"
        if: steps.skip_check.outputs.skip == 'false'
        run: |
          cd ml
          python train_exec_quality.py ../${{ env.DATA_DIR }}/candidates.merged.parquet models

      - name: "🤖 Train RL Position Sizer"
        if: steps.skip_check.outputs.skip == 'false'
        run: |
          cd ml
          python train_rl_sizer.py ../${{ env.DATA_DIR }}/candidates.merged.parquet models

      - name: "📊 Calculate Model Checksums"
        if: steps.skip_check.outputs.skip == 'false'
        id: sums
        run: |
          cd ml
          echo "ver=$(date +%Y%m%d_%H%M%S)_${{ github.run_number }}" >> $GITHUB_OUTPUT
          echo "meta_sha=$(sha256sum models/meta_model.onnx | cut -d' ' -f1 || echo 'none')" >> $GITHUB_OUTPUT
          echo "exec_sha=$(sha256sum models/exec_model.onnx | cut -d' ' -f1 || echo 'none')" >> $GITHUB_OUTPUT  
          echo "rl_sha=$(sha256sum models/rl_model.onnx | cut -d' ' -f1 || echo 'none')" >> $GITHUB_OUTPUT
          
          echo "📊 Model checksums calculated:"
          ls -la models/

      - name: "☁️ Upload Models to S3"
        if: steps.skip_check.outputs.skip == 'false'
        run: |
          cd ml
          
          # Upload versioned models
          for model in models/*.onnx; do
            if [ -f "$model" ]; then
              basename=$(basename "$model" .onnx)
              aws s3 cp "$model" "s3://${{ secrets.S3_BUCKET }}/models/$basename/v${{ steps.sums.outputs.ver }}.onnx" --acl public-read
              echo "Uploaded $model"
            fi
          done
          
          # Upload scalers and other artifacts
          for artifact in models/*.pkl models/*.npy; do
            if [ -f "$artifact" ]; then
              aws s3 cp "$artifact" "s3://${{ secrets.S3_BUCKET }}/models/artifacts/$(basename '$artifact')" --acl public-read
              echo "Uploaded $(basename '$artifact')"
            fi
          done
          
          echo "☁️ Uploaded models to S3"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          
      - name: "📋 Publish Secure Model Manifest"
        if: steps.skip_check.outputs.skip == 'false'
        run: |
          cd ml
          
          # Create unsigned manifest
          cat > models/current_unsigned.json <<EOF
          {
            "version": "${{ steps.sums.outputs.ver }}",
            "timestamp": "$(date -u --iso-8601=seconds)",
            "training_samples": $(wc -l < "../${{ env.DATA_DIR }}/candidates.merged.parquet" 2>/dev/null || echo 1000),
            "models": {
              "meta": {
                "url": "${{ secrets.CDN_BASE_URL }}/models/meta_model/v${{ steps.sums.outputs.ver }}.onnx",
                "checksum": "${{ steps.sums.outputs.meta_sha }}",
                "size": $(stat -c%s "models/meta_model.onnx" 2>/dev/null || echo 0),
                "createdAt": "$(date -u --iso-8601=seconds)"
              },
              "execution": {
                "url": "${{ secrets.CDN_BASE_URL }}/models/exec_model/v${{ steps.sums.outputs.ver }}.onnx", 
                "checksum": "${{ steps.sums.outputs.exec_sha }}",
                "size": $(stat -c%s "models/exec_model.onnx" 2>/dev/null || echo 0),
                "createdAt": "$(date -u --iso-8601=seconds)"
              },
              "rl_sizer": {
                "url": "${{ secrets.CDN_BASE_URL }}/models/rl_model/v${{ steps.sums.outputs.ver }}.onnx",
                "checksum": "${{ steps.sums.outputs.rl_sha }}",
                "size": $(stat -c%s "models/rl_model.onnx" 2>/dev/null || echo 0),
                "createdAt": "$(date -u --iso-8601=seconds)"
              }
            },
            "strategies": ["EmaCrossStrategy", "MeanReversion", "Breakout", "Momentum"],
            "features": {
              "count": 17,
              "list": ["price", "atr", "rsi", "ema20", "ema50", "volume", "spread", "volatility", "bid_ask_imbalance", "order_book_imbalance", "tick_direction", "signal_strength", "prior_win_rate", "avg_r_multiple", "drawdown_risk", "news_impact", "liquidity_risk"]
            }
          }
          EOF
          
          # Sign manifest using HMAC tool
          echo "🔐 Signing manifest with HMAC-SHA256..."
          python ../tools/sign_manifest.py \
            --manifest models/current_unsigned.json \
            --key "${{ secrets.MANIFEST_HMAC_KEY }}" \
            --add-to-manifest
          
          # Copy signed manifest to final location
          cp models/current_unsigned.json models/current.json
          
          # Upload signed manifest
          aws s3 cp models/current.json "s3://${{ secrets.S3_BUCKET }}/models/current.json" \
            --acl public-read \
            --content-type application/json \
            --cache-control "max-age=300"
            
          echo "📋 Published secure model manifest with HMAC signature"
          echo "🔐 Manifest preview:"
          head -20 models/current.json
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          
      - name: "🏁 Training Summary"
        if: steps.skip_check.outputs.skip == 'false'
        run: |
          echo "🎉 24/7 Cloud Training Completed Successfully!"
          echo "📊 Version: ${{ steps.sums.outputs.ver }}"
          echo "📈 Models trained and uploaded to S3"
          echo "🔐 Manifest signed and published to CDN"
          echo "✅ Ready for bot consumption via ModelUpdaterService"
