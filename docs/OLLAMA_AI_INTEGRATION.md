# Trading Bot AI Conversation Integration

## Overview

The trading bot now has conversational AI capabilities powered by Ollama, allowing it to:
- **Explain trading decisions** before execution
- **Reflect on trade outcomes** after completion
- Speak naturally as itself (not as an external observer)
- Provide context-aware explanations based on current market conditions

## Components Added

### 1. OllamaClient (`src/BotCore/Services/OllamaClient.cs`)
A service that communicates with the Ollama AI service to generate natural language explanations.

**Features:**
- Configurable Ollama endpoint and model
- Async API communication
- Connection health checking
- Comprehensive error handling

### 2. Enhanced UnifiedTradingBrain (`src/BotCore/Brain/UnifiedTradingBrain.cs`)
The trading brain now includes:
- Optional OllamaClient dependency injection
- `GatherCurrentContext()` - Collects current market state
- `ThinkAboutDecisionAsync()` - Explains why taking a trade
- `ReflectOnOutcomeAsync()` - Reflects on completed trades

## Configuration

Add these environment variables to your `.env` file:

```bash
# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma2:2b

# Enable AI Features
BOT_THINKING_ENABLED=true
BOT_REFLECTION_ENABLED=true
```

### Configuration Options

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_BASE_URL` | `http://localhost:11434` | Ollama service endpoint |
| `OLLAMA_MODEL` | `gemma2:2b` | AI model to use |
| `BOT_THINKING_ENABLED` | `false` | Enable pre-trade explanations |
| `BOT_REFLECTION_ENABLED` | `false` | Enable post-trade reflections |

## Setup Instructions

### 1. Install Ollama

```bash
# Install Ollama (if not already installed)
curl https://ollama.ai/install.sh | sh

# Pull the recommended model
ollama pull gemma2:2b
```

### 2. Start Ollama Service

```bash
# Start Ollama in the background
ollama serve
```

### 3. Enable AI Features

Update your `.env` file:

```bash
BOT_THINKING_ENABLED=true
BOT_REFLECTION_ENABLED=true
```

### 4. Register OllamaClient (Optional - if not auto-registered)

In `Program.cs` or your DI container setup:

```csharp
services.AddSingleton<OllamaClient>();
```

## Usage

### Before Trade Execution

When `BOT_THINKING_ENABLED=true`, the bot logs its thought process:

```
ðŸ’­ [BOT-THINKING] I'm entering this LONG position because the market is showing strong bullish momentum 
with high volume confirmation. My S2 VWAP strategy has identified a mean reversion opportunity, and 
current VIX levels suggest stable market conditions favorable for this trade setup.
```

### After Trade Completion

When `BOT_REFLECTION_ENABLED=true`, the bot reflects on outcomes:

```
ðŸ”® [BOT-REFLECTION] This trade closed at my stop loss after 45 minutes. The market moved against my 
entry as volatility spiked unexpectedly. I'll adjust my VIX threshold for similar setups in the future.
```

## Example Log Output

```
ðŸ§  [BRAIN-DECISION] ES: Strategy=S2 (72.5%), Direction=Up (68.0%), Size=1.20x, Regime=Trending, Time=234ms
ðŸ’­ [BOT-THINKING] I'm taking this S2 VWAP mean reversion trade because I see a strong deviation 
from VWAP with high volume support. My current performance is strong today with 75% win rate, 
and the bullish trend aligns with my strategy specialization.
âœ… [TRADE-SUCCESS] Decision executed successfully
...
ðŸ“š [UNIFIED-LEARNING] ES S2: PnL=$125.50, Correct=True, WinRate=78%, TotalTrades=12
ðŸ”® [BOT-REFLECTION] Great trade! The market respected the VWAP support level perfectly, and my 
entry timing was optimal during the morning session. This validates my strategy's edge in 
trending markets with good volume.
```

## Architecture

### Decision Flow with AI

```
1. Market Analysis â†’ UnifiedTradingBrain.MakeIntelligentDecisionAsync()
2. Generate Decision
3. [NEW] If BOT_THINKING_ENABLED â†’ ThinkAboutDecisionAsync()
4.   - Gather market context (VIX, P&L, trend, strategies)
5.   - Generate AI explanation
6.   - Log thinking
7. Execute Trade
8. Trade Completes
9. [NEW] If BOT_REFLECTION_ENABLED â†’ ReflectOnOutcomeAsync()
10.   - Analyze outcome (WIN/LOSS, P&L, duration)
11.   - Generate AI reflection
12.   - Log reflection
```

### Context Information

The AI has access to:
- **VIX Level** - Market volatility indicator
- **Today's P&L** - Current profitability
- **Win Rate** - Success percentage
- **Market Trend** - Bullish/Bearish/Neutral
- **Active Strategies** - Which strategies are enabled
- **Decision Count** - Number of trades today
- **Trade Details** - Entry, stop, target, strategy name

## Performance Considerations

- AI calls are **async and non-blocking**
- Failures are **gracefully handled** (bot continues without AI)
- Network timeouts: 30 seconds
- Ollama must be running locally (or at configured endpoint)
- If Ollama is unavailable, bot operates normally without AI features

## Troubleshooting

### Ollama Not Connected

**Symptom:** No AI output, but bot runs normally

**Solution:**
1. Check if Ollama is running: `ps aux | grep ollama`
2. Test endpoint: `curl http://localhost:11434/api/tags`
3. Start Ollama: `ollama serve`

### Wrong Model

**Symptom:** Slow responses or errors

**Solution:**
1. Verify model is pulled: `ollama list`
2. Pull correct model: `ollama pull gemma2:2b`
3. Update `.env` if using different model

### No AI Output

**Symptom:** Bot runs but no ðŸ’­ or ðŸ”® logs

**Solution:**
1. Check environment variables are set to `true`
2. Verify OllamaClient is registered in DI container
3. Check logs for connection errors

## Safety & Production Considerations

âœ… **Optional Feature** - Bot works with or without Ollama
âœ… **Non-Blocking** - AI failures don't affect trading
âœ… **Graceful Degradation** - Falls back to normal operation
âœ… **Configurable** - Can enable/disable per environment
âœ… **No Trading Impact** - AI is for explanation only

## Future Enhancements

Potential improvements:
- News sentiment integration
- Learning from past AI suggestions
- Interactive conversation mode
- Trade idea generation
- Risk assessment explanations

## Code Examples

### Manual Usage

```csharp
// Inject OllamaClient
var ollamaClient = serviceProvider.GetService<OllamaClient>();

// Check connection
bool isConnected = await ollamaClient.IsConnectedAsync();

// Ask a question
string response = await ollamaClient.AskAsync("Explain this market condition...");
```

### Integration in Custom Services

```csharp
public class MyTradingService
{
    private readonly OllamaClient? _ollamaClient;

    public MyTradingService(OllamaClient? ollamaClient = null)
    {
        _ollamaClient = ollamaClient;
    }

    public async Task AnalyzeMarketAsync()
    {
        if (_ollamaClient != null)
        {
            var analysis = await _ollamaClient.AskAsync(
                "What does high VIX mean for my strategy?"
            );
            _logger.LogInformation("AI Analysis: {Analysis}", analysis);
        }
    }
}
```

## References

- [Ollama Documentation](https://ollama.ai/docs)
- [Gemma 2 Model](https://ollama.ai/library/gemma2)
- `src/BotCore/Services/OllamaClient.cs`
- `src/BotCore/Brain/UnifiedTradingBrain.cs`
